{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second try, Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "#Standarts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath   = r'D:\\Downloads\\NIH'\n",
    "imagepath = r'D:\\Downloads\\NIH\\images-224\\3channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>058Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>058Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>058Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>081Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>081Y</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0  00000001_000.png            Cardiomegaly            0           1   \n",
       "1  00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2  00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3  00000002_000.png              No Finding            0           2   \n",
       "4  00000003_000.png                  Hernia            0           3   \n",
       "\n",
       "  Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0        058Y              M            PA                 2682     2749   \n",
       "1        058Y              M            PA                 2894     2729   \n",
       "2        058Y              M            PA                 2500     2048   \n",
       "3        081Y              M            PA                 2500     2048   \n",
       "4        081Y              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  \n",
       "0                        0.143  0.143  \n",
       "1                        0.143  0.143  \n",
       "2                        0.168  0.168  \n",
       "3                        0.171  0.171  \n",
       "4                        0.143  0.143  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(csvpath,'Data_Entry_2017.csv')).drop(['Unnamed: 11'], axis = 1)\n",
    "errorlist = pd.read_csv('errorlist.csv')\n",
    "df.set_index('Image Index', inplace = True)\n",
    "df.drop(index = errorlist['0'], inplace = True, axis = 0)\n",
    "df.reset_index(inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|')[0] if '|' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASS_NAMES = pd.get_dummies(df['Finding Labels']).columns\n",
    "CLASS_NAMES = ['Cardiomegaly', 'Nodule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Sex</th>\n",
       "      <th>View</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>058Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>058Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>058Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>081Y</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>081Y</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image Index Finding Labels  Follow-up #  Patient ID Patient Age  \\\n",
       "0  00000001_000.png   Cardiomegaly            0           1        058Y   \n",
       "1  00000001_001.png   Cardiomegaly            1           1        058Y   \n",
       "2  00000001_002.png   Cardiomegaly            2           1        058Y   \n",
       "3  00000002_000.png     No Finding            0           2        081Y   \n",
       "4  00000003_000.png         Hernia            0           3        081Y   \n",
       "\n",
       "  Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0              M            PA                 2682     2749   \n",
       "1              M            PA                 2894     2729   \n",
       "2              M            PA                 2500     2048   \n",
       "3              M            PA                 2500     2048   \n",
       "4              F            PA                 2582     2991   \n",
       "\n",
       "   OriginalImagePixelSpacing[x     y]  Sex  View  \n",
       "0                        0.143  0.143    0     0  \n",
       "1                        0.143  0.143    0     0  \n",
       "2                        0.168  0.168    0     0  \n",
       "3                        0.171  0.171    0     0  \n",
       "4                        0.143  0.143    1     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex']  = pd.get_dummies(df['Patient Gender'])['F']\n",
    "df['View'] = pd.get_dummies(df['View Position'])['AP']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'D:\\Downloads\\NIH\\images-224\\3channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'D:\\\\Downloads\\\\NIH\\\\images-224\\\\3channel\\\\Nodule\\\\00028966_000.png'\n",
      "b'D:\\\\Downloads\\\\NIH\\\\images-224\\\\3channel\\\\Cardiomegaly\\\\00001330_000.png'\n",
      "b'D:\\\\Downloads\\\\NIH\\\\images-224\\\\3channel\\\\Cardiomegaly\\\\00016291_031.png'\n",
      "b'D:\\\\Downloads\\\\NIH\\\\images-224\\\\3channel\\\\Cardiomegaly\\\\00001911_013.png'\n",
      "b'D:\\\\Downloads\\\\NIH\\\\images-224\\\\3channel\\\\Cardiomegaly\\\\00023246_000.png'\n"
     ]
    }
   ],
   "source": [
    "for f in list_ds.take(5):\n",
    "    print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5382"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(list(list_ds))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(file_path):    #Demora muito, temos que refinar\n",
    "    #get the metadata\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    mdt = tf.int8([df[df['Image Index'] == parts[-1]]['Sex'].values, df[df['Image Index'] == parts[-1]]['View'].values])\n",
    "    return mdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    mtd = get_metadata(file_path)\n",
    "    return img, mtd, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-16-2fc9c69afec4>:6 process_path  *\n        mtd = get_metadata(file_path)\n    <ipython-input-22-5ebdf5fad822>:4 get_metadata  *\n        mdt = tf.int8([df[df['Image Index'] == parts[-1]]['Sex'].values, df[df['Image Index'] == parts[-1]]['View'].values])\n\n    TypeError: 'DType' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-654f03079f48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mAUTOTUNE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlabeled_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1591\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3926\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3139\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-16-2fc9c69afec4>:6 process_path  *\n        mtd = get_metadata(file_path)\n    <ipython-input-22-5ebdf5fad822>:4 get_metadata  *\n        mdt = tf.int8([df[df['Image Index'] == parts[-1]]['Sex'].values, df[df['Image Index'] == parts[-1]]['View'].values])\n\n    TypeError: 'DType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "        ds = ds.cache(cache)\n",
    "    else:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeled_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-454a83aba65c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_for_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'labeled_ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds = prepare_for_training(labeled_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch, metadata = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-24e639ad62ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batchn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-c86243b4251c>\u001b[0m in \u001b[0;36mshow_batch\u001b[1;34m(image_batch, label_batch)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCLASS_NAMES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_batch(image_batch.numpy(), label_batchn.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),          #Adicionar metadados aqui\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in converted code:\n\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2481 _standardize_tensors\n        feed_sample_weight_modes)\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2480 <listcomp>\n        for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:964 standardize_weights\n        if sample_weight is not None and len(sample_weight.shape) != 1:\n\n    AttributeError: '_NestedVariant' object has no attribute 'shape'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-63c6cef193e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m history = model.fit(train_ds, \n\u001b[0;32m      4\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     epochs=epochs)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Note that the dataset instance is immutable, its fine to reusing the user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    682\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1591\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3926\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3139\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in converted code:\n\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2481 _standardize_tensors\n        feed_sample_weight_modes)\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2480 <listcomp>\n        for (ref, sw, cw, mode) in zip(y, sample_weights, class_weights,\n    C:\\Users\\Licon\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:964 standardize_weights\n        if sample_weight is not None and len(sample_weight.shape) != 1:\n\n    AttributeError: '_NestedVariant' object has no attribute 'shape'\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "history = model.fit(train_ds, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the image model\n",
    "image_processor =  tf.keras.Sequential()\n",
    "image_processor.add(base_model)\n",
    "image_processor.add(tf.keras.layers.Dropout(0.2))\n",
    "image_processor.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "image_processor.add(tf.keras.layers.Flatten())  # transform image to vector\n",
    "\n",
    "# Now we create the metadata model\n",
    "metadata_processor =  tf.keras.Sequential()\n",
    "metadata_processor(tf.keras.layers.InputLayer((None, 2)))\n",
    "... # maybe more?\n",
    "# Now we concatenate the two features and add a few more layers on top\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Concatenate([image_processor, metadata_processor]))  # Merge is your sensor fusion buddy\n",
    "model.add(tf.keras.layers.Dense(15, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.dataset_ops._NestedVariant object at 0x00000297F22B8F08>\n"
     ]
    }
   ],
   "source": [
    "for img, lb, mt in train_ds.take(1):\n",
    "    print(mt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.1",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
