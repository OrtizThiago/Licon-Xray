{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvpath  = r'D:\\Downloads\\NIH\\Data_Entry_2017.csv'\n",
    "base_dir = r'D:\\Downloads\\NIH\\images-224\\3channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metadata\n",
    "df = pd.read_csv(csvpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images path\n",
    "all_image_paths = {os.path.basename(x): x for x in\n",
    "                        glob(os.path.join(base_dir, '*', '*.png'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path col to df\n",
    "df['path'] = df['Image Index'].map(all_image_paths.get)\n",
    "\n",
    "#Remove 'Y' from patients' age\n",
    "df['Patient Age'] = df['Patient Age'].map(lambda x: int(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get just the firs diagnosis \n",
    "df['Finding Labels'] = df['Finding Labels'].apply(lambda x: x.split('|')[0] if '|' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels (['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'].\n"
     ]
    }
   ],
   "source": [
    "# labels binary coding\n",
    "labels = np.unique(df['Finding Labels'])\n",
    "labels = [x for x in labels if len(x)>0]\n",
    "print('Labels ({}.'.format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_label in labels:\n",
    "    if len(c_label) > 1:  # leave out empty labels\n",
    "        df[c_label] = df['Finding Labels'].map(\n",
    "            lambda finding: 1.0 if c_label in finding else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dummies of Patient's gender and view position\n",
    "\n",
    "df['Gender'] = pd.get_dummies(df['Patient Gender'])['F']\n",
    "df['View']   = pd.get_dummies(df['View Position'])['AP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path']           = df['path'].astype('str')\n",
    "df['Finding Labels'] = df['Finding Labels'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df[['path', 'Finding Labels', 'Gender', 'View']], \n",
    "                                test_size = 0.3, \n",
    "                                random_state = 42,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold(dataframe = train, BATCH_SIZE = 32, x_cols = ['path', 'Gender', 'View'], y_cols = ['path']):\n",
    "    kfold = KFold(n_splits=(dataframe.shape[0]//BATCH_SIZE)+1, shuffle=True, random_state= 42)\n",
    "    k_split = kfold.split(X = dataframe[['path', 'Gender', 'View']], y = dataframe['Finding Labels'])\n",
    "    return k_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_split = get_kfold(train, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(dataframe, kfold):\n",
    "    batch = next(kfold)\n",
    "    df = dataframe.iloc[batch[1]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = get_next_batch(train, k_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_idg = tf.keras.preprocessing.image.ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=5, \n",
    "                              shear_range = 0.1,\n",
    "                              fill_mode = 'reflect',\n",
    "                              zoom_range=0.15,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(dataframe, x_col = 'path', mtd_cols = ['Gender', 'View'], BATCH_SIZE = BATCH_SIZE):\n",
    "    train_gen = core_idg.flow_from_dataframe(dataframe, \n",
    "                                         directory=None,\n",
    "                                         x_col = 'path',\n",
    "                                         y_col = 'Finding Labels',\n",
    "                                         class_mode = 'categorical',\n",
    "                                         classes = labels,\n",
    "                                         target_size = IMG_SIZE,\n",
    "                                         #color_mode = 'grayscale',\n",
    "                                         batch_size = dataframe.shape[0])\n",
    "    mtd = dataframe[mtd_cols].values\n",
    "    return train_gen, mtd.reshape(BATCH_SIZE,2,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 validated image filenames belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen, mtd = prepare_for_training(train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data generation done!\n"
     ]
    }
   ],
   "source": [
    "trainx, trainy = next(train_gen)\n",
    "print('data generation done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainy = keras.utils.to_categorical(trainy).reshape(BATCH_SIZE,2,15) Use only if there is no Dense layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 4d473c1dd8becc155b73f8504c6f6626 so we will re-download the data.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 208s 2us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False, \n",
    "    input_shape=(224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define the image model\n",
    "image_processor =  tf.keras.Sequential()\n",
    "image_processor.add(base_model)\n",
    "image_processor.add(tf.keras.layers.Dropout(0.2))\n",
    "image_processor.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "image_processor.add(tf.keras.layers.Dropout(0.5))\n",
    "image_processor.add(tf.keras.layers.Dense(512))\n",
    "#image_processor.add(keras.layers.Flatten())\n",
    "\n",
    "\n",
    "# Now we create the metadata model\n",
    "mtd_processor = tf.keras.Sequential()\n",
    "mtd_processor.add(tf.keras.layers.InputLayer(input_shape=(2,1)))\n",
    "mtd_processor.add(tf.keras.layers.Dropout(0.5))\n",
    "mtd_processor.add(tf.keras.layers.Dense(10))\n",
    "mtd_processor.add(tf.keras.layers.Flatten())\n",
    "\n",
    "added = tf.keras.layers.concatenate([image_processor.output, mtd_processor.output])\n",
    "\n",
    "#added = keras.layers.Add()([image_processor.output, mtd_processor.output])\n",
    "out = tf.keras.layers.Dense(15, activation='softmax')(added)\n",
    "model = tf.keras.models.Model(inputs = [image_processor.input, mtd_processor.input], outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 13s 204ms/sample - loss: 4.1061 - accuracy: 0.3594\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 4.1073 - accuracy: 0.3125\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 3.9017 - accuracy: 0.2188\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 2.9101 - accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 7s 108ms/sample - loss: 3.1001 - accuracy: 0.2500\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 7s 113ms/sample - loss: 2.1327 - accuracy: 0.3750\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 7s 107ms/sample - loss: 2.3638 - accuracy: 0.4062\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 7s 114ms/sample - loss: 2.1079 - accuracy: 0.3125\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 7s 109ms/sample - loss: 2.0394 - accuracy: 0.3594\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 2.1218 - accuracy: 0.3594\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 2.1154 - accuracy: 0.3594\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.9541 - accuracy: 0.4375\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7693 - accuracy: 0.4688\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8151 - accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8168 - accuracy: 0.4688\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.9262 - accuracy: 0.3750\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8851 - accuracy: 0.4375\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.9984 - accuracy: 0.3125\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8077 - accuracy: 0.3906\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7618 - accuracy: 0.4688\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8211 - accuracy: 0.4375\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7959 - accuracy: 0.4531\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7274 - accuracy: 0.4531\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7344 - accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8163 - accuracy: 0.4375\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7361 - accuracy: 0.4531\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7758 - accuracy: 0.4531\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 1.8043 - accuracy: 0.4688\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6775 - accuracy: 0.4375\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7957 - accuracy: 0.4688\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6932 - accuracy: 0.4219\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7248 - accuracy: 0.4688\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 1.7300 - accuracy: 0.4531\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 7s 105ms/sample - loss: 1.7004 - accuracy: 0.4688\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 1.6116 - accuracy: 0.4844\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6708 - accuracy: 0.4688\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7505 - accuracy: 0.4375\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7405 - accuracy: 0.4688\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7037 - accuracy: 0.4688\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7011 - accuracy: 0.4375\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6576 - accuracy: 0.4531\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6173 - accuracy: 0.4844\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.5993 - accuracy: 0.4844\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6414 - accuracy: 0.4531\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6439 - accuracy: 0.4219\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6641 - accuracy: 0.3750\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 1.6447 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.5907 - accuracy: 0.4219\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 1.6273 - accuracy: 0.4375\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.5340 - accuracy: 0.4844\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.4437 - accuracy: 0.4844\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.5955 - accuracy: 0.4375\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.9075 - accuracy: 0.3281\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7342 - accuracy: 0.4219\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6974 - accuracy: 0.4375\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7641 - accuracy: 0.4062\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6174 - accuracy: 0.4531\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.5482 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7752 - accuracy: 0.4062\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7373 - accuracy: 0.3750\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7394 - accuracy: 0.4688\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 7s 106ms/sample - loss: 1.7749 - accuracy: 0.3906\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8178 - accuracy: 0.4688\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6874 - accuracy: 0.4844\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7284 - accuracy: 0.4062\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6552 - accuracy: 0.4531\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7650 - accuracy: 0.4531\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7617 - accuracy: 0.4062\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8829 - accuracy: 0.4375\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7516 - accuracy: 0.3750\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 7s 107ms/sample - loss: 1.6881 - accuracy: 0.4688\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 7s 108ms/sample - loss: 1.7609 - accuracy: 0.4531\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 7s 106ms/sample - loss: 1.7221 - accuracy: 0.4375\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 7s 105ms/sample - loss: 1.7350 - accuracy: 0.4062\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 7s 105ms/sample - loss: 1.6474 - accuracy: 0.4844\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 7s 105ms/sample - loss: 1.7617 - accuracy: 0.4531\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 7s 104ms/sample - loss: 1.7278 - accuracy: 0.4219\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 7s 107ms/sample - loss: 1.7649 - accuracy: 0.4219\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 7s 106ms/sample - loss: 1.7231 - accuracy: 0.4062\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6937 - accuracy: 0.3906\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7593 - accuracy: 0.4219\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7179 - accuracy: 0.4375\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6851 - accuracy: 0.4688\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7601 - accuracy: 0.4688\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6919 - accuracy: 0.4531\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6702 - accuracy: 0.4688\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6891 - accuracy: 0.3906\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7313 - accuracy: 0.4219\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7502 - accuracy: 0.4062\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7284 - accuracy: 0.4219\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6204 - accuracy: 0.4531\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.6430 - accuracy: 0.4844\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7840 - accuracy: 0.4375\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7005 - accuracy: 0.4531\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7341 - accuracy: 0.4375\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8578 - accuracy: 0.3438\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 7s 105ms/sample - loss: 1.6056 - accuracy: 0.4688\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.8179 - accuracy: 0.4062\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7850 - accuracy: 0.4219\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 7s 103ms/sample - loss: 1.7966 - accuracy: 0.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f61fcbd08>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [trainx, mtd], y = trainy,\n",
    "                    steps_per_epoch = 64, \n",
    "                    epochs = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
